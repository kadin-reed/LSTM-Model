import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

# Activation functions and derivatives
def sigmoid(x):
    return 1 / (1 + np.exp(-x))

def sigmoid_derivative(x):
    return sigmoid(x) * (1 - sigmoid(x))

def tanh(x):
    return np.tanh(x)

def tanh_derivative(x):
    return 1 - np.tanh(x) ** 2

# Create dataset function
def create_dataset(dataset, sequence_length=1):
    X, Y = [], []
    for i in range(len(dataset) - sequence_length - 1):
        seq_X = dataset[i:(i + sequence_length), 0]
        seq_Y = dataset[i + sequence_length, 0]
        X.append(seq_X)
        Y.append(seq_Y)
    return np.array(X), np.array(Y)

# LSTM Cell class
class LSTMCell:
    def __init__(self, input_dim, num_neurons, output_dim):
        self.num_neurons = num_neurons

        # Initialize weights
        self.W_forget = np.random.randn(num_neurons, num_neurons + input_dim)
        self.b_forget = np.zeros((num_neurons, 1))

        self.W_input = np.random.randn(num_neurons, num_neurons + input_dim)
        self.b_input = np.zeros((num_neurons, 1))

        self.W_cell_candidate = np.random.randn(num_neurons, num_neurons + input_dim)
        self.b_cell_candidate = np.zeros((num_neurons, 1))

        self.W_output = np.random.randn(num_neurons, num_neurons + input_dim)
        self.b_output = np.zeros((num_neurons, 1))

        self.W_output_layer = np.random.randn(output_dim, num_neurons)
        self.b_output_layer = np.zeros((output_dim, 1))
    
    # Foward method 
    def forward(self, input_sequence, prev_hidden_state, prev_cell_state):
        combined_input = np.concatenate((prev_hidden_state, input_sequence), axis=0)

        self.forget_gate = sigmoid(np.dot(self.W_forget, combined_input) + self.b_forget)
        self.input_gate = sigmoid(np.dot(self.W_input, combined_input) + self.b_input)
        self.cell_candidate = tanh(np.dot(self.W_cell_candidate, combined_input) + self.b_cell_candidate)
        self.output_gate = sigmoid(np.dot(self.W_output, combined_input) + self.b_output)

        self.cell_state = self.forget_gate * prev_cell_state + self.input_gate * self.cell_candidate
        self.hidden_state = self.output_gate * tanh(self.cell_state)

        output = np.dot(self.W_output_layer, self.hidden_state) + self.b_output_layer
        return self.hidden_state, self.cell_state, output

    # Backward method 
    def backward(self, input_sequence, prev_hidden_state, prev_cell_state, cell_state, hidden_state, output, target, learning_rate=0.001):
        d_output = output - target

        d_W_output_layer = np.dot(d_output, hidden_state.T)
        d_b_output_layer = d_output

        d_hidden_state = np.dot(self.W_output_layer.T, d_output)
        d_output_gate = d_hidden_state * tanh(cell_state)
        d_output_gate = d_output_gate * sigmoid_derivative(self.output_gate)

        d_cell_state = d_hidden_state * self.output_gate * tanh_derivative(tanh(cell_state))
        d_forget_gate = d_cell_state * prev_cell_state
        d_input_gate = d_cell_state * self.cell_candidate

        d_cell_candidate = d_cell_state * self.input_gate
        d_cell_candidate = d_cell_candidate * tanh_derivative(self.cell_candidate)

        d_W_forget = np.dot(d_forget_gate, np.concatenate((prev_hidden_state, input_sequence), axis=0).T)
        d_b_forget = d_forget_gate
        d_W_input = np.dot(d_input_gate, np.concatenate((prev_hidden_state, input_sequence), axis=0).T)
        d_b_input = d_input_gate
        d_W_cell_candidate = np.dot(d_cell_candidate, np.concatenate((prev_hidden_state, input_sequence), axis=0).T)
        d_b_cell_candidate = d_cell_candidate
        d_W_output = np.dot(d_output_gate, np.concatenate((prev_hidden_state, input_sequence), axis=0).T)
        d_b_output = d_output_gate

        self.W_forget -= learning_rate * d_W_forget
        self.b_forget -= learning_rate * d_b_forget
        self.W_input -= learning_rate * d_W_input
        self.b_input -= learning_rate * d_b_input
        self.W_cell_candidate -= learning_rate * d_W_cell_candidate
        self.b_cell_candidate -= learning_rate * d_b_cell_candidate
        self.W_output -= learning_rate * d_W_output
        self.b_output -= learning_rate * d_b_output
        self.W_output_layer -= learning_rate * d_W_output_layer
        self.b_output_layer -= learning_rate * d_b_output_layer

# Normalize dataset
def normalize(data):
    min_val = np.min(data, axis=0)
    max_val = np.max(data, axis=0)
    return (data - min_val) / (max_val - min_val), min_val, max_val

def inverse_normalize(data, min_val, max_val):
    return data * (max_val - min_val) + min_val

# Training method
def train_lstm(trainX, trainY, sequence_length, epochs=50, learning_rate=0.001):
    input_dim = sequence_length
    num_neurons = 4
    output_dim = 1
    
    lstm = LSTMCell(input_dim, num_neurons, output_dim)
    
    hidden_state = np.zeros((num_neurons, 1))
    cell_state = np.zeros((num_neurons, 1))
    
    for epoch in range(epochs):
        total_loss = 0
        for i in range(len(trainX)):
            input_sequence = trainX[i].reshape(-1, 1)
            target = trainY[i].reshape(-1, 1)
            
            hidden_state, cell_state, output = lstm.forward(input_sequence, hidden_state, cell_state)
            
            loss = (output - target) ** 2
            total_loss += loss
            
            # Backward pass to update weights
            lstm.backward(input_sequence, hidden_state, cell_state, cell_state, hidden_state, output, target, learning_rate)
        
        print(f'Epoch {epoch+1}/{epochs}, Loss: {total_loss.item()}')

    return lstm

# Prediction method
def predict(lstm, dataX, sequence_length):
    predictions = []
    hidden_state = np.zeros((lstm.num_neurons, 1))
    cell_state = np.zeros((lstm.num_neurons, 1))
    
    for i in range(len(dataX)):
        input_sequence = dataX[i].reshape(-1, 1)
        hidden_state, cell_state, output = lstm.forward(input_sequence, hidden_state, cell_state)
        predictions.append(output.item())
    
    return np.array(predictions)

# Loads Dataset
def load_data(filepath):
    df = pd.read_csv(filepath, usecols=[1,2,3,4,5,6,7,8,9,10,11])
    data = df.values
    return data


def main():
    filepath = 'AllData.txt'
    data = load_data(filepath)
    
    
    data, min_val, max_val = normalize(data)
    
    # Split all data into training and test sets
    train_size = int(len(data) * 0.67)
    test_size = len(data) - train_size
    train, test = data[0:train_size], data[train_size:len(data)]
    
   
    sequence_length = 3
    trainX, trainY = create_dataset(train, sequence_length)
    testX, testY = create_dataset(test, sequence_length)
    
    lstm = train_lstm(trainX, trainY, sequence_length, epochs=100)
    
    trainPredict = predict(lstm, trainX, sequence_length)
    testPredict = predict(lstm, testX, sequence_length)
    
    
    trainPredict = inverse_normalize(trainPredict, min_val[0], max_val[0])
    testPredict = inverse_normalize(testPredict, min_val[0], max_val[0])
    trainY = inverse_normalize(trainY, min_val[0], max_val[0])
    testY = inverse_normalize(testY, min_val[0], max_val[0])
    
    # X-axis settings
    num_data_points = data.shape[0]
    years = np.linspace(2014, 2022, num=num_data_points)
    
  
    plt.figure(figsize=(12, 6))
    plt.plot(years, inverse_normalize(data[:, 0], min_val[0], max_val[0]), label='True Data')
    
    trainPredictPlot = np.empty_like(data[:, 0])
    trainPredictPlot[:] = np.nan
    trainPredictPlot[sequence_length:len(trainPredict)+sequence_length] = trainPredict
    plt.plot(years, trainPredictPlot, label='Train Prediction')
    
    testPredictPlot = np.empty_like(data[:, 0])
    testPredictPlot[:] = np.nan
    testPredictPlot[len(trainPredict)+(sequence_length*2)+1:len(data)-1] = testPredict
    plt.plot(years, testPredictPlot, label='Test Prediction')
    
    # Graph legends
    plt.xlabel('Year')
    plt.ylabel('Energy Output (kWh)')
    plt.title('LSTM Model Predictions vs True Data')
    plt.legend()
    plt.grid(True)
    
    # Set x-axis to show only years from 2014 to 2022
    plt.xlim(2014, 2022)
    
    plt.show()

if __name__ == "__main__":
    main()
